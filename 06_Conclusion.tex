\chapter{Conclusion}
\label{chapter:conclusion}

In this research, we develop a set of methods to optimize the execution of large scale scientific workflows in public clouds with both cost and deadline constrains. We accomplish this goal through the following two-step approach: 

In the first step, we present a set of methods to optimize the execution of scientific workflow in public clouds, with the Montage astronomical mosaic engine running on Amazon EC2 as an example. In this study, we use DEWE v1 to carry out our experiments. The main contributions of the step are:

\begin{itemize}
	\item Workflow visualization techniques can be used to generate the resource consumption pattern, as well as identify the bottleneck of a workflow. 
	\item Compiler optimization can be used as general approach to optimize the execution of a scientific workflow. 
	\item The bottleneck identified can be further optimized with code level parallelization techniques. The results show that parallelism is the primary source of performance gain in modern computing systems.
	\item On Amazon EC2, further makespan reduction can be achieved by using different cluster configurations without impact on cost. Since Montage workflows are also I/O intensive, additional performance gain can be achieved using RAID 0, which improves I/O performance through parallelism of read/write operations.
\end{itemize}
	
In the second step, we address three main challenges in realizing benefits of using public clouds when executing large-scale workflow ensembles: (1) execution coordination, (2) resource provisioning, and (3) data staging. To this end, we develop DEWE v2 as a pulling-based workflow execution system that is capable of executing large scale scientific workflow ensembles in public clouds. The specific contributions of this step are:

\begin{itemize}
	\item By adopting the pulling approach in our solution system, we have demonstrated that much of scheduling overhead when executing a large-scale workflow ensemble particularly in public clouds can be removed as a majority of tasks in scientific workflows often exhibit homogeneity in their resource consumption pattern and acquiring a large number of homogeneous public cloud resources is easily possible. We compare the performance of DEWE v2 with Pegasus showing DEWE v2 is capable of achieving 80\% speed-up. We have also demonstrated that provisioning cloud resources using our profiling-based strategy based on performance index is very effective in terms of both cost and deadline compliance.
	\item In experiments with a single 6.0 degree Montage workflow, DEWE v2 is capable of achieving 50\% speed-up as compared to Pegasus. In experiments with Montage workflow ensembles, DEWE v2 is capable of achieving 80\% speed-up as compared to Pegasus. This demonstrates that the pulling approach has better performance over the scheduling approach in executing large scale scientific workflow ensembles in public clouds. In the case of workflow ensembles, further speed-up can be achieved using workflow job submission techniques as opposed to batch submission in DEWE v2.
	\item For large scale workflow ensembles, the optimal amount of computing resources can be calculated using the concept of performance index, which is derived from profiling applications in small scale testings. The largest workflow ensemble tested includes 200 6.0 degree Montage workflows, which contains 1,717,200 jobs, 288,800 input files, and 4,570,000 intermediate files. Approximately 7.0 TB data is written to the underlying storage during the execution. Small scale testings with 20 6.0 degree Montage workflows (10\% of the large scale experiment) are used to derive the performance indexes of different EC2 instance types. The derived performance indexes is then used to calculate the number of worker nodes needed for the large scale experiments. This technique is proven to be effective in meeting both cost and deadline constraints. 
\end{itemize}
